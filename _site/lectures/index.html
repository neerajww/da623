<!DOCTYPE html>
<html>

  <head>
  




  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title> Lectures - DA623 Computing with Signals / Jan-May 2023 </title>
  <meta name="description" content="Lectures - DA623 Computing with Signals / Jan-May 2023">
  
  <link rel="stylesheet" href="/da623/_css/main.css">
  <link rel="canonical" href="http://localhost:4000/da623/lectures/">
  <link rel="alternate" type="application/rss+xml" title="DA623 Computing with Signals / Jan-May 2023 - MFSDSAI, IITG" href="http://localhost:4000/da623/feed.xml" />
<link rel='stylesheet' id='open-sans-css'  href='//fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>




<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper" style="z-index: 100;">
      <table><tr>
          <td><img width="75" src="/da623/_images/logo.png" valign="middle"></td>
          <td style="padding-left:10px;"><a class="schoolname" style="font-size: 15px;" class="site-title" href="https://www.iitg.ac.in/dsai/home">MFSDSAI, IITG</a>
          <br/>
          <span style="margin-top: -2px;margin-bottom: -10px;" class="site-title"><a href="/da623/" title="DA623 Computing with Signals / Jan-May 2023 - MFSDSAI, IITG"><b>DA623 Computing with Signals</a></b></span>
          <br/>
          <span class="coursesemeter" style="font-size: 12px;font-weight: bold;margin-top: 10px;display: block;">Jan-May 2023</span>
          </td>
        </tr></table>

    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Main Navigation</h1>

 <ul class="menu">
    
    <li>
        <a class="page-link" href="/da623/">
            <i class="fa fa-home fa-lg"></i> Home
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da623/schedule/">
            <i class="fas fa-calendar-alt"></i> Schedule
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da623/lectures/">
            <i class="fas fa-book-reader"></i> Lectures
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da623/assignments/">
            <i class="fas fa-user-graduate"></i> Assignments
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da623/project/">
            <i class="fas fa-user-graduate"></i> Project
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da623/materials/">
            <i class="fas fa-book"></i> Materials
        </a>
    </li>
    
</ul>

     </div>  
    </nav>

  </div>

  <div class="header-texture" style="height:100%; z-index: 0; position: absolute; top:0; right: 0; left: 0; 
  background-image: url('/da623/_images/pattern.png');" />

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Lectures</h1>
  </header>

  <article class="post-content">
    <p>You can download the lectures here. We will try to upload lectures prior to their corresponding classes.</p>


<ul id="archive">

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-0) Introduction</span><br>

        <strong>tl;dr:</strong> Introduction to computer vision and logistics of this course.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-0.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://medium.com/hackernoon/a-brief-history-of-computer-vision-and-convolutional-neural-networks-8fe8aacc79f3">A brief history of CV by Rostyslav Demush</a></li>
  <li><a href="https://szeliski.org/Book">Chapter-1 of CVAA2E book by Richard Szeliski</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-1) Image Classification</span><br>

        <strong>tl;dr:</strong> Image Classification, a fundamental task of computer vision and simple algorithms to solve it.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-1.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-2) Optimization</span><br>

        <strong>tl;dr:</strong> Process of finding the best parameters.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-2.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-3) Neural Networks - Perceptron</span><br>

        <strong>tl;dr:</strong> Basic Artificial Neuron: MP neuron and Perceptron.
        <br/>
        <strong>
        
    
    
    [<a title="Download perceptron-code" href="
    
      https://colab.research.google.com/drive/1y6X4MnS3NNmYr3MthOYsGdpB-A3ixhzg?usp=sharing 
    ">perceptron-code</a>]
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-3.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://www.cse.iitb.ac.in/~shivaram/teaching/old/cs344+386-s2017/resources/classnote-1.pdf">Perceptron convergence proof</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-4) Neural Networks - MLP</span><br>

        <strong>tl;dr:</strong> Multi-Layered Network of Perceptrons.
        <br/>
        <strong>
        
    
    
    [<a title="Download perceptron-code" href="
    
      https://colab.research.google.com/drive/1y6X4MnS3NNmYr3MthOYsGdpB-A3ixhzg?usp=sharing 
    ">perceptron-code</a>]
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-4.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-5) Backpropagation</span><br>

        <strong>tl;dr:</strong> Elegant technique that implements the gradient descent algorithm for the neural network training.
        <br/>
        <strong>
        
    
    
    [<a title="Download Tensor-basics-code" href="
    
      https://colab.research.google.com/drive/1i__UOd8nLu4GdKf9PoT_w3ORVvGcgQAq?usp=sharing 
    ">Tensor-basics-code</a>]
    
    [<a title="Download Autograd-example-code" href="
    
      https://colab.research.google.com/drive/1TwTX3QN2mp3JYvPgRIpUzkiHjKOA0aM_?usp=sharing 
    ">Autograd-example-code</a>]
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-5.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://kmopuri.github.io/dlc/static_files/presentations/dlc-1.2.pdf">5min-Tensor-basics</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-6) Building blocks of CNNs</span><br>

        <strong>tl;dr:</strong> Modules that constitute a Convolutional Neural Network (CNN)
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-6.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://github.com/puzzler10/simple_pytorch_cnn/blob/master/cifar10_cnn.ipynb">Simple CNN training</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-7) CNN Architectures</span><br>

        <strong>tl;dr:</strong> Evolution of the design principles and the resulting CNN architectures.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-7.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/1605.07678">Analysis of DNN models for practical applications</a></li>
  <li><a href="https://arxiv.org/abs/1611.05431">Aggregated Residual Transformations for Deep Neural Networks</a></li>
  <li><a href="https://www.youtube.com/watch?v=NaoVOOhVC3w">Trimps-Soushen-1, Shao et al. ILSVRC 2016</a></li>
  <li><a href="https://towardsdatascience.com/review-trimps-soushen-winner-in-ilsvrc-2016-image-classification-dfbc423111dd">Trimps-Soushen-2, Shao et al. ILSVRC 2016</a></li>
  <li><a href="https://arxiv.org/abs/1709.01507">Squeeze-and-Excitation Networks</a></li>
  <li><a href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Networks</a></li>
  <li><a href="https://arxiv.org/abs/1704.04861">MobileNets</a></li>
  <li><a href="https://arxiv.org/abs/1707.01083">ShuffleNets</a></li>
  <li><a href="https://research.google/pubs/pub45826/">NAS</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-8) Training DNNs</span><br>

        <strong>tl;dr:</strong> Important aspects of training deep neural networks.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-8.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Xavier Initialization</a></li>
  <li><a href="https://openreview.net/forum?id=H1gsz30cKX">Fixup Initialization: Residual learning without Normalization</a></li>
  <li><a href="https://jmlr.org/papers/v15/srivastava14a.html">Dropout by Srivastave et al.</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-9) Training DNNs-II</span><br>

        <strong>tl;dr:</strong> Some more important aspects of training deep neural networks.
        <br/>
        <strong>
        
    
    
    [<a title="Download sgd_update_rules.gif" href="
    
      /da623/static_files/sgd_update_rules.gif 
    ">sgd_update_rules.gif</a>]
    
    [<a title="Download Codes-Update rules implementation" href="
    
      https://colab.research.google.com/drive/1__iXdKpepXortelx06I35RYfnu94Dg4t?usp=sharing 
    ">Codes-Update rules implementation</a>]
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-9.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://ruder.io/optimizing-gradient-descent/">Optimization update rules by Sebastian Ruder</a></li>
  <li><a href="https://proceedings.mlr.press/v28/sutskever13.html">SGD with Momentum, I Sutskever et al. ICML 2013</a></li>
  <li><a href="https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Ada Grad, Duchi et al. JMLR, 2011</a></li>
  <li><a href="https://arxiv.org/abs/1412.6980">Adam, Kingma et al. ICLR 2015</a></li>
  <li><a href="https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10">Some insgihts about lr in dl</a></li>
  <li><a href="https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">Random search for hyper-parameter selection, Bergstra, JMLR 2012</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-10) RNNs</span><br>

        <strong>tl;dr:</strong> Beyond the feed-forward neural nets, processing sequential data!
        <br/>
        <strong>
        
    
    
    [<a title="Download Sample-sequential-task" href="
    
      https://colab.research.google.com/drive/1OHmvKM7wINUS9kBDQExY_oDKK4AX-wgN?usp=sharing 
    ">Sample-sequential-task</a>]
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1dTK-1HCj9gsW4R8T0vLisckF44GUET-gg02uaRDaT44/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>

<ul>
  <li><a href="http://www.bioinf.jku.at/publications/older/2604.pdf">LSTM Hochreiter et al. 1997</a></li>
  <li><a href="https://arxiv.org/abs/1409.3215">Sequence to sequence learning by Sutskever et al. 2014</a></li>
  <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation with aligning by Bahdanau et al. ICLR 2015</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-11) Attention</span><br>

        <strong>tl;dr:</strong> Attention in sequence-to-sequence tasks using RNNs.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-11.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/1409.3215">Sequence to sequence learning by Sutskever et al. NeurIPS 2014</a></li>
  <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation with aligning by Bahdanau et al. ICLR 2015</a></li>
  <li><a href="https://arxiv.org/pdf/1502.03044.pdf">Show Attend and Tell by Xu et al. 2015</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-12) Word Embeddings</span><br>

        <strong>tl;dr:</strong> Representing words in the NLP reltaed tasks
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-12.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-13) Visualizing and Understanding CNNs</span><br>

        <strong>tl;dr:</strong> What do the CNNs learn? Why the predict what they predict?
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1er4y7u7jDXEDsB3mEkxhyZ9UVMjub6CkuN3xj_9RKLM/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>

<ul>
  <li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf">Rich Feature Hierarchies by Girshick et al. CVPR 2014</a></li>
  <li><a href="https://arxiv.org/abs/1311.2901">Visualizing and Understanding CNNs by Zeiler and Fergus ECCV 2014</a></li>
  <li><a href="https://arxiv.org/abs/1312.6034">Deep Inside CNNs by Simonyan et al. ICLRW 2014</a></li>
  <li><a href="http://cnnlocalization.csail.mit.edu/">Class Activation Maps (CAM) by B Zhou et al. CVPR 2016</a></li>
  <li><a href="http://gradcam.cloudcv.org/">Grad-CAM by Selvaraju et al. NIPSW 2016, ICCV 2017</a></li>
  <li><a href="https://arxiv.org/abs/1708.06670">CNN-Fixations by Mopuri et al. TIP 2018</a></li>
  <li><a href="https://arxiv.org/abs/1505.07376">Texture Synthesis using CNNs by Gatys et al. NeurIPS 2015</a></li>
  <li><a href="https://github.com/google/deepdream">DeepDream</a></li>
  <li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf">Neural style transfer by Gatys et al. CVPR 2016</a></li>
  <li><a href="https://arxiv.org/abs/1412.0035">Understanding Deep Representations by Inverting them by A Mahendran et al. CVPR 2015</a></li>
  <li><a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Dosovitskiy_Inverting_Visual_Representations_CVPR_2016_paper.pdf">Inverting Visual Representations with CNNs by A Dosovitskiy et al. CVPR 2016</a>-</li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-14) Object Detection</span><br>

        <strong>tl;dr:</strong> Task of simultaneously locating and classifying multiple pbjects present in an image using CNNs.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1AQpa0ZIuewV4JjCS8-0DHMxfJoPY6MeK-zkNoUMJT5c/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://arxiv.org/pdf/1311.2524.pdf">R-CNN by Girshick et al. CVPR 2014</a></li>
  <li><a href="https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html">Fast R-CNN by Girshick ICCV 2015</a></li>
  <li><a href="https://arxiv.org/abs/1506.01497">Faster R-CNN by Ren et al. NeurIPS 2015</a></li>
  <li><a href="https://github.com/weiliu89/caffe/tree/ssd">SSD by Liu et al. ECCV 2016</a></li>
  <li><a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf">YOLO by Redmon et al. CVPR 2016</a></li>
  <li><a href="https://arxiv.org/abs/1611.10012">Comparison of CNN object detectors by Huang et al. CVPR 2017</a></li>
  <li><a href="https://arxiv.org/abs/1808.01244">CornerNet by Law et al. ECCV 2018</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-15) Semantic Segmentation</span><br>

        <strong>tl;dr:</strong> Objective is to label each pixel present in an image using CNNs.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1BApQ0icWbVov3aLd_x8pVD9xYJezCktiTp5gn15BnaA/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://arxiv.org/pdf/1411.4038.pdf">FCN by Long et al. CVPR 2015</a></li>
  <li><a href="https://arxiv.org/pdf/1505.04366.pdf">Deconvolution for semantic segmentation by Noh et al. ICCV 2015</a></li>
  <li><a href="https://kmopuri.github.io/dlc/static_files/presentations/dlc-7.1.pdf">Transposed Convolutions</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-16) Video Classification</span><br>

        <strong>tl;dr:</strong> Recognize the actions in videos using CNNs.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1BHn7ois-zFQNcO5FZ7C0_0Aul3Fv940_8z8AW1O8PwQ/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-17) Generative Models</span><br>

        <strong>tl;dr:</strong> ML models that understand and model the data.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1z3sJCOlI1PIC5lA0zgZX64sHNxjDo6EF6KtEfli-Cc0/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://arxiv.org/pdf/1601.06759.pdf">Pixel RNN, Google DeepMind, ICML 2016</a></li>
  <li><a href="https://arxiv.org/pdf/1606.05328.pdf">Pixel CNN, Google DeepMind, NeurIPS 2016</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-17a) Autoencoders</span><br>

        <strong>tl;dr:</strong> Neural Networks that encode unlabeled data into lower dimensional subspaces driven by the reconstruction objective.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-17a.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-17b) Variational Autoencoder</span><br>

        <strong>tl;dr:</strong> Stochastic modules of an Autoencoder makes it a generative model.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      /da623/static_files/presentations/dl4cv-17b.pdf 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://arxiv.org/pdf/1312.6114.pdf">Auto-Encoding Variational Bayes, ICLR 2014</a></li>
  <li><a href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73">Blogpost on VAE</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-17c) Generative Adversarial Networks</span><br>

        <strong>tl;dr:</strong> Generative models with implicit density modeling for generating samples that resemble real data.
        <br/>
        <strong>
        
    
    
    [<a title="Download example-code" href="
    
      https://colab.research.google.com/drive/1f5-Ho5fwtn20_PCe1nw4PvaEr8BWsAJF?usp=sharing 
    ">example-code</a>]
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1vRXEopsE7dRgeXTEuBK8zQcKT1enhWAtE3MNF-e5wDw/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        <p><strong>Suggested Readings:</strong></p>
<ul>
  <li><a href="https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">GANs, Goodfellow et al, NIPS 2014</a></li>
  <li><a href="https://github.com/hindupuravinash/the-gan-zoo">GAN Zoo</a></li>
</ul>

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-18) Adversarial Images</span><br>

        <strong>tl;dr:</strong> Inputs that are crafted (via adding a special noise) to fool the trained DL systems.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/110zccEdyvqbeBAEbcrgbeuWNKRCDvL46zoXU0AK-3CY/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-19) Learning Efficient DL Models (Compressing the Models)</span><br>

        <strong>tl;dr:</strong> Making the power hungry and huge models light-weight.
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/1f9Qs46a9CTprZIkbd8WQ57QlsI5WV91jLyzfHJh-P1I/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

<li class="archiveposturl" style="background: transparent">
<div class="lecture-container">
    
    <div class="content">
        <span style="font-weight: bold;">(dl4cv-20) Attetion++</span><br>

        <strong>tl;dr:</strong> Attention is all that we need?!
        <br/>
        <strong>
        
    
    
    [<a title="Download slides" href="
    
      https://docs.google.com/presentation/d/15ifYMrvQtDrp20H8JWbP94Tifh8OWHlxXt1hiGfpyh0/edit?usp=sharing 
    ">slides</a>]
    
    

        </strong>

        
        <br/>
        <div class="markdown-content" style="margin-top: 3px;">
        

        </div>
        
    </div>
</div>
</li>

</ul>
  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

<!--     <h2 class="footer-heading">MFSDSAI, IITG</h2> -->
         <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
 

         <p class="text">
Mehta Family School of Data Science and Artificial Intelligence<br />
IIT Guwahati, India<br />

      </div>

      <div class="footer-col  footer-col-2">
       <ul class="social-media-list">
     

          

          

          

          

          
  <li>
    <a href="https://www.iitg.ac.in/dsai/home">
      <i class="fas fa-globe" style="color:gray"></i> iitg.ac.in/dsai/home
    </a>
  </li>




       
        </ul>
      </div>
    </div>

  </div>

</footer>

  </body>

</html>
<!-- d.s.m.s.050600.062508.030515.080516.030818 | "Baby, I'm Yours" -->